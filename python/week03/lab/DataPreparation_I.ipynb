{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ThjuJ3gXEKYr"
   },
   "source": [
    "# MLAH Week 3 Lab - Data Preparation I\n",
    "In this session we will focus on data input and output using __Pandas__.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "xk-aG7faIKhm"
   },
   "outputs": [],
   "source": [
    "#Your code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PaQohSKYFcD1"
   },
   "source": [
    "## Task 1. Reading Data in Text Format\n",
    "__Pandas__ features a number of functions for reading tabular data as a DataFrame object, `read_csv` and `read_table` are the ones that we will be using the most. \n",
    "\n",
    "As data in the real world can be messy, some of the data loading functions (especially `read_csv`) have grown very complex in their options over time. The online __Pandas__ [documentation](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html) has details and examples about how each of them works, so if you are struggling to read a particular file, there might be a similar enough example to help you find the right parameters.\n",
    "\n",
    "Some of these functions, like `pandas.read_csv`, perform *type inference*, because the column data types are not part of the data format. This means you do not necessarily have to specify which columns are numeric, integer, boolean, or string. Other data formats, like HDF5, Feather, and msgpack, have the data types stored in the format.\n",
    "\n",
    "### 1.1 Import Pandas into your project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "LxiGw4VQDtcg"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TSwnQUf2JejH"
   },
   "source": [
    "### 1.2 Use `read_csv` to load data files\n",
    "\n",
    "Handling dates and other custom types can require extra effort. Let us start with a small comma-separated (CSV) text file. \n",
    "\n",
    "*   Load the *ex1.csv* dummy data into a named `DataFrame`. Check [Doc](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html) if you need some help (The example is at the bottom of the page)\n",
    "*   Display the table\n",
    "*   Compare the `DataFrame` with the raw csv file. Think about how this raw csv text file has been formatted into a `DataFrame`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "UXzkssMrK6-7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>hello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>foo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a   b   c   d message\n",
       "0  1   2   3   4   hello\n",
       "1  5   6   7   8   world\n",
       "2  9  10  11  12     foo"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('ex1(2).csv')\n",
    "df\n",
    "\n",
    "# converted first row in the raw file as coulmms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "elMsJZGQLxrd"
   },
   "source": [
    "### 1.3 Use `read_table` to load the same csv data file\n",
    "\n",
    "\n",
    "*   Load the same *ex1.csv* dummy data into another named `DataFrame` by using `read_table`\n",
    "*   List item\n",
    "*   If you get a different `DataFrame` format compared with above, you may forget to specifiy the _Delimiter_. CSV files use ',' to seperate columns but `read_table` uses `Tab`('\\t') by default. In [Doc](https://pandas.pydata.org/docs/reference/api/pandas.read_table.html), please check how to define _Delimiter_ for CSV files.\n",
    "*   Make sure your `DataFrame` in this step is the same as using `read_csv`\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Fzm9182INskr"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>hello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>foo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a   b   c   d message\n",
       "0  1   2   3   4   hello\n",
       "1  5   6   7   8   world\n",
       "2  9  10  11  12     foo"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_table('ex1(2).csv',sep=\",\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AiSsGXv7Sy14"
   },
   "source": [
    "In some cases, a table might not have a fixed delimiter, using whitespace or some other pattern to separate fields. We can still use `sep=` options but pass the __regular expression__ instead. \n",
    "\n",
    "Check [Doc](https://docs.python.org/3/library/re.html) and some [examples](https://www.w3schools.com/python/python_regex.asp) for more information about the __reguluar expression__\n",
    "\n",
    "\n",
    "\n",
    "*   Check *ex3.txt* raw file. The fields here are separated by a variable amount of whitespace. In these cases, you can pass a regular expression `\\s+`\n",
    "*   Notice that there was one fewer column name than the number of data rows, `read_table` infers that the first column should be the DataFrame’s index in this special case.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Nlojl24yUq95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               A         B         C\n",
      "0  aaa -0.264438 -1.026059 -0.619500\n",
      "1  bbb  0.927272  0.302904 -0.032399\n",
      "2  ccc -0.264273 -0.386314 -0.217601\n",
      "3  ddd -0.871858 -0.348382  1.100491\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aaa</th>\n",
       "      <td>-0.264438</td>\n",
       "      <td>-1.026059</td>\n",
       "      <td>-0.619500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bbb</th>\n",
       "      <td>0.927272</td>\n",
       "      <td>0.302904</td>\n",
       "      <td>-0.032399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ccc</th>\n",
       "      <td>-0.264273</td>\n",
       "      <td>-0.386314</td>\n",
       "      <td>-0.217601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ddd</th>\n",
       "      <td>-0.871858</td>\n",
       "      <td>-0.348382</td>\n",
       "      <td>1.100491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            A         B         C\n",
       "aaa -0.264438 -1.026059 -0.619500\n",
       "bbb  0.927272  0.302904 -0.032399\n",
       "ccc -0.264273 -0.386314 -0.217601\n",
       "ddd -0.871858 -0.348382  1.100491"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('ex3(1).csv')\n",
    "print(df)\n",
    "df = pd.read_table('ex3(1).csv',sep='\\s+')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7lIKrbOjOE0e"
   },
   "source": [
    "### 1.4 Read files without headers\n",
    "A file will not always have a header row. Check the raw *ex2.csv* file, the first row is not the header row.\n",
    "\n",
    "`read_csv` will recognise the first row as header by default. To ignore the headers, use `header = None` as part of the parameters. \n",
    "\n",
    "*   Load *ex2.csv* by using `load_csv`\n",
    "*   Make sure the headers are ignored\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Qf6IShscP6lb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0   1   2   3      4\n",
      "0  1   2   3   4  hello\n",
      "1  5   6   7   8  world\n",
      "2  9  10  11  12    foo\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('ex2(2).csv', header=None)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q0XkCQpjQJN0"
   },
   "source": [
    "You can use `names=[your name list]` optional parameters to specify headers for this file.\n",
    "*  Specify the headers with your own __String List__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A   B   C   D Message\n",
      "0  1   2   3   4   hello\n",
      "1  5   6   7   8   world\n",
      "2  9  10  11  12     foo\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('ex2(2).csv', names=['A', 'B', 'C', 'D','Message'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZOoNt8IVvVe"
   },
   "source": [
    "### 1.5 Skip rows\n",
    "\n",
    "Many data sheets contains unwanted data. You can skip certain rows of a file with `skiprows` options\n",
    "\n",
    "\n",
    "*   Use `skiprows=[the row index to skip]` to skip the first, third and fourth rows when reading *ex4.csv*\n",
    "*   Display the table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "J27kerG-RI5T"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A   B   C   D Message\n",
      "0  9  10  11  12     foo\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('ex2(2).csv', names=['A', 'B', 'C', 'D','Message'], skiprows=[0,1])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yaFos0TxW8Ji"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G31q4Fv6qQIF"
   },
   "source": [
    "## 2. Data Cleaning\n",
    "\n",
    "Sometimes the way that data is stored in files or databases is not in the correct format, for a particular task. \n",
    "\n",
    "Fortunately, pandas, along with the built-in Python language features, provide you with a high-level, flexible, and fast set of tools to enable you to manipulate data into the right form.\n",
    "\n",
    "If you identify a type of data manipulation that is not anywhere in this notebook or elsewhere in the pandas library, feel free to share your use case on the Pandas GitHub site. Indeed, much of the design and implementation of Pandas has been driven by the needs of real-world applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fP6gvkQerhe5"
   },
   "source": [
    "### 2.1 Filtering Out Missing Data\n",
    "\n",
    "As we mentioned in the lecture, you should always assume your dataset has missing data. One common practice is to drop out the missing data from your dataset. In __Pandas__, you can use `DataFrame.dropna` [Doc](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html).  \n",
    "\n",
    "\n",
    "\n",
    "> As a side note, you always have the option to do it from lower level function and indexing methods by hand using `pandas.isnull` and __boolean indexing__ see this [link](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#boolean-indexing) for more about boolean indexing. You can check the same page for more advanced indexing techniques. \n",
    "\n",
    "We will use the following `data` example for this practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "id": "Nm866b9ZuXcU",
    "outputId": "71a08e71-6af9-423f-e3d5-d5d7894b8f3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2\n",
      "0  1.0  6.5  3.0\n",
      "1  NaN  NaN  NaN\n",
      "2  NaN  NaN  NaN\n",
      "3  1.0  6.5  3.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from numpy import nan\n",
    "data = pd.DataFrame([[1., 6.5, 3.], [nan, nan, nan],\n",
    "                     [nan, nan, nan], [1, 6.5, 3.]])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YeZ6r8AjvZhH"
   },
   "source": [
    "\n",
    "\n",
    "*   `dropna` is an `DataFrame` object function, call this funtion from the above `data` object\n",
    "*   Keep the \"cleaned\" output somewhere else and display it\n",
    "*   Compare with the `data`, what has been dropped?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "zSGUiue2vclR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2\n",
      "0  1.0  6.5  3.0\n"
     ]
    }
   ],
   "source": [
    "print(data.dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nxgDEVL4wjoB"
   },
   "source": [
    "\n",
    "\n",
    "*   Passing `how='all'` will only drop rows that are all NA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "9I7BmVdVwnuK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2\n",
      "0  1.0  6.5  3.0\n",
      "1  1.0  NaN  NaN\n",
      "3  NaN  6.5  3.0\n"
     ]
    }
   ],
   "source": [
    "print(data.dropna(how='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PAa21ToGxNTY"
   },
   "source": [
    "By default, the function will drop rows. If you want to drop columns, you can pass `axis = 1` in the functions optional parameters\n",
    "\n",
    "\n",
    "> Many functions use `axis` to indicate whether the operation is on the __rows__ or __columns__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2\n",
      "0  1.0  6.5  3.0\n",
      "3  1.0  6.5  3.0\n"
     ]
    }
   ],
   "source": [
    "print(data.dropna(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "paeiZL0ZyZA-"
   },
   "source": [
    "Suppose you want to keep only rows containing a certain number of observations. You can also set up `thresh` to indicate this. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "id": "E7H_h9r3zBOx",
    "outputId": "f1b5354f-950f-49ca-b513-434846da8ad2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.126661</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.662663</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.425985</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.863164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.213309</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.458469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.161122</td>\n",
       "      <td>1.232639</td>\n",
       "      <td>0.747123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.196424</td>\n",
       "      <td>0.015630</td>\n",
       "      <td>1.304408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.060712</td>\n",
       "      <td>-1.421740</td>\n",
       "      <td>0.860028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2\n",
       "0 -1.126661       NaN       NaN\n",
       "1  0.662663       NaN       NaN\n",
       "2 -1.425985       NaN -0.863164\n",
       "3  0.213309       NaN  1.458469\n",
       "4  0.161122  1.232639  0.747123\n",
       "5  0.196424  0.015630  1.304408\n",
       "6 -0.060712 -1.421740  0.860028"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame(np.random.randn(7, 3))\n",
    "df.iloc[:4, 1] = nan\n",
    "df.iloc[:2, 2] = nan\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c1ch3S01za-5"
   },
   "source": [
    "\n",
    "\n",
    "*   Test `thresh = X` (you can try X=1,2,3 or 4) in the `dropna` function and compare the output\n",
    "\n",
    "\n",
    "> Tip: Combine `axis = 1` will set up this threshold for columns\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2\n",
      "0 -1.126661       NaN       NaN\n",
      "1  0.662663       NaN       NaN\n",
      "2 -1.425985       NaN -0.863164\n",
      "3  0.213309       NaN  1.458469\n",
      "4  0.161122  1.232639  0.747123\n",
      "5  0.196424  0.015630  1.304408\n",
      "6 -0.060712 -1.421740  0.860028\n"
     ]
    }
   ],
   "source": [
    "# non-NA values 유효한 값수 axis=0 행, axis=1컬럼\n",
    "print(df.dropna(thresh=3, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fdNywGHi0Fry"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TDYypNTm0-pL"
   },
   "source": [
    "### 2.2 Filling In Missing Data\n",
    "\n",
    "Rather than filtering out missing data (and potentially discarding other data along with it), you may want to fill in the “holes” in any number of ways. For most purposes, the `fillna` method is the workhorse function to use [Doc](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.fillna.html). Calling `fillna` with a constant replaces missing values with that value\n",
    "\n",
    "Let's still use `df` from previous example\n",
    "\n",
    "\n",
    "\n",
    "*   Fill the NaN of `df` with a constant replacement (such as 0)\n",
    "*   Display the filled new `DataFrame`\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "WGubGbmW4rHb"
   },
   "source": [
    "\n",
    "> Calling `fillna` with a `dict` ([Doc](https://www.w3schools.com/python/python_dictionaries.asp)), you can use a different fill value for each column. For example `\n",
    "` means fill column 1 with 0.5 and column 2 with 1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2\n",
      "0 -1.126661  0.500000  1.000000\n",
      "1  0.662663  0.500000  1.000000\n",
      "2 -1.425985  0.500000 -0.863164\n",
      "3  0.213309  0.500000  1.458469\n",
      "4  0.161122  1.232639  0.747123\n",
      "5  0.196424  0.015630  1.304408\n",
      "6 -0.060712 -1.421740  0.860028\n"
     ]
    }
   ],
   "source": [
    "print(df.fillna({1:0.5, 2:1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f6iCW6Cj3wJ6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJTAPoYg54PG"
   },
   "source": [
    "You can also fill holes (*i.e.* a part of the column are all NaN) by using \n",
    "* `method='ffill'` : propagate last valid observation forward to next valid observation.  \n",
    "* `method='bfill'` : use next valid observation to fill gap backwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "H1CWnMfv68Nv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2\n",
      "0 -1.126661       NaN       NaN\n",
      "1  0.662663       NaN       NaN\n",
      "2 -1.425985       NaN -0.863164\n",
      "3  0.213309       NaN  1.458469\n",
      "4  0.161122  1.232639  0.747123\n",
      "5  0.196424  0.015630  1.304408\n",
      "6 -0.060712 -1.421740  0.860028\n"
     ]
    }
   ],
   "source": [
    "print(df.fillna(method='ffill'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e09cHVrnkMJd"
   },
   "source": [
    "## 3 Replacing Values\n",
    "\n",
    "Filling in missing data with the `fillna` method is a special case of more general value replacement. In this task, we will use `replace` [Doc](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html) to provide a simpler and more flexible way to replace values.\n",
    "\n",
    "Let us considering the following dummy `Seriers`, which is similar to `DataFrame` but it only contains one column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "elfsX2BslZgh",
    "outputId": "693c7d45-6a72-4edc-fab7-77a8cafe7265"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1.0\n",
       "1    -999.0\n",
       "2       2.0\n",
       "3    -999.0\n",
       "4   -1000.0\n",
       "5       3.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.Series([1., -999.,2.,-999,-1000,3.])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mgBUZN3Hl-V8"
   },
   "source": [
    "The -999 values might be sentinel values for missing data. To replace these with NaN values that pandas understands, we can use replace, producing a new Series (unless you pass `inplace=True`):\n",
    "\n",
    "\n",
    "*   Use `replace(to_replace=XXX, value=YYY)` to replace -999 by NaN\n",
    "*   Display your results\n",
    "*   (You may need to import numpy.nan first)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1.0\n",
       "1       NaN\n",
       "2       2.0\n",
       "3       NaN\n",
       "4   -1000.0\n",
       "5       3.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.replace(to_replace=-999, value=nan, inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e1mjX-yxmMZf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ISpg8sMBnd59"
   },
   "source": [
    "We can also use, `replace`  with `list` and `dict`, and `to_replace=` and `value=` parameters to have powerful replacement operations. Please check the offical link from [here](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html). Check all their examples, especially the cases with `Strings`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XL75EFvMptK1"
   },
   "source": [
    "## 4. Clean Sheffield House Price Dataset\n",
    "\n",
    "The House Price Dataset, we cerated last session needs __a lot of__ cleaning. \n",
    "*   Load the data to a `DataFrame`\n",
    "*   Use `DataFrame` memtober `dtypes` to check the data type of each column. (You may not want to see the price data to be String/Object, can you figure out the reason?)\n",
    "*   You can always monitor the `dtypes` after each operation\n",
    "*   Create your data preparation process by using __Pandas__ functions \n",
    "\n",
    "---\n",
    "\n",
    "Some recommended processing\n",
    "\n",
    "\n",
    "*   Change the long headers (be programmer friendly )\n",
    "*   Remove/fill/replace missing data from 'Size (Sq M)'\n",
    "*   Change the data type of 'Number of Bedrooms' to integer\n",
    "*   Simplify the items in the 'House Type'\n",
    "*   Formating the Price. You can use the `replace` method with regular expression. You can also try some [alternative method](https://pbpython.com/currency-cleanup.html)\n",
    "*   Formatting the 'Postcode', for example, to only show area code. For some extra reading, please check this [wiki](https://en.wikipedia.org/wiki/Postcodes_in_the_United_Kingdom#Validation). It is not required for our task but it is always good to learn new things!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode bytes in position 15-16: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18293/4278260407.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'House Price.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1233\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1234\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1235\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1236\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_dtype_objs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode bytes in position 15-16: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('House Price.csv')\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of DataPreparation_lab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
